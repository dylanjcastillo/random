{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import hdbscan\n",
    "import pandas as pd\n",
    "\n",
    "from langchain import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from newsapi import NewsApiClient\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get 200 news articles from relevant sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsapi = NewsApiClient(api_key=os.getenv(\"NEWSAPI_API_KEY\"))\n",
    "sources_1 = [\n",
    "    \"the-washington-post\",\n",
    "    \"the-wall-street-journal\",\n",
    "    \"business-insider\",\n",
    "]\n",
    "sources_2 = [\n",
    "    \"associated-press\",\n",
    "    \"bloomberg\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_articles = []\n",
    "for source in [sources_1, sources_2]:\n",
    "    recent_articles.extend(newsapi.get_everything(\n",
    "        sources=\",\".join(source),\n",
    "        language=\"en\",\n",
    "        page_size=100\n",
    "    )[\"articles\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate embeddings from news articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    a[\"title\"] + \"\\n\\n\" + a[\"description\"]\n",
    "    for a in recent_articles\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(chunk_size=1000).embed_documents(docs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster documents and store the results in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdb = hdbscan.HDBSCAN(gen_min_span_tree=True, min_samples=3, min_cluster_size=3).fit(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"title\": [article[\"title\"] for article in recent_articles],\n",
    "    \"description\": [article[\"description\"] for article in recent_articles],\n",
    "    \"cluster\": hdb.labels_,\n",
    "})\n",
    "df = df.query(\"cluster != -1\") # Remove documetns that are not in a cluster"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create cluster topics from documents in each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_prompt():\n",
    "    system_template = \"You're an expert journalist. You're helping me write a compelling topic title for news articles.\"\n",
    "    human_template = \"Using the following articles, write a topic title that summarizes them.\\n\\nARTICLES:{articles}\\n\\nTOPIC TITLE:\"\n",
    "\n",
    "    return ChatPromptTemplate(\n",
    "        messages=[\n",
    "            SystemMessagePromptTemplate.from_template(system_template),\n",
    "            HumanMessagePromptTemplate.from_template(human_template),\n",
    "        ],\n",
    "        input_variables=[\"articles\"],\n",
    "    )\n",
    "\n",
    "\n",
    "articles_str = \"\\n\\n\".join(\n",
    "    [article[\"title\"] + \"\\n\\n\" + article[\"description\"] for article in recent_articles]\n",
    ")\n",
    "\n",
    "prompt = get_prompt()\n",
    "\n",
    "for c in df.cluster.unique():\n",
    "    chain = LLMChain(\n",
    "        llm=ChatOpenAI(temperature=0, model_name=\"gpt-4\"), prompt=prompt, verbose=False\n",
    "    )\n",
    "    articles_str = \"\\n\".join(\n",
    "        [\n",
    "            f\"{article['title']}\\n{article['description']}\\n\"\n",
    "            for article in df.query(f\"cluster == {c}\").to_dict(orient=\"records\")\n",
    "        ]\n",
    "    )\n",
    "    result = chain.run(\n",
    "        {\n",
    "            \"articles\": articles_str,\n",
    "        }\n",
    "    )\n",
    "    df.loc[df.cluster == c, \"topic_title\"] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 6\n",
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    print(df.query(f\"cluster == {c}\").topic_title.values[0])\n",
    "    display(df.query(f\"cluster == {c}\").head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
